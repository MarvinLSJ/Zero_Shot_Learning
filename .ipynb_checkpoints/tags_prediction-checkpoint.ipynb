{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, GlobalMaxPooling2D, ZeroPadding2D, Input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read train file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all_train: {image file name - image tag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_path = \"data/0813/DatasetA_train_20180813\"\n",
    "test_root_path = \"data/0813/DatasetA_test_20180813/DatasetA_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = pd.read_csv(os.path.join(train_root_path, 'train.txt'), sep='\\t', header=None)\n",
    "all_train.columns = ['filename', 'tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to image file name in all_train, get image in order  \n",
    "X_train: {image in array}, in shape (image_count, height, width, channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-divided Train and Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/0813/DatasetA_train_20180813/train/2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d24c7a658ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#遍历文件夹\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    493\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    494\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 495\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2547\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2548\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2549\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/0813/DatasetA_train_20180813/train/2fb89ef2ace869d3eb3bdd3afe184e1c.jpeg'"
     ]
    }
   ],
   "source": [
    "Y_train = pd.read_csv(os.path.join(train_root_path, 'train_local.txt'), sep='\\t', header=None)\n",
    "Y_train.columns = ['filename', 'tag']\n",
    "\n",
    "Y_valid = pd.read_csv(os.path.join(train_root_path, 'dev_local.txt'), sep='\\t', header=None)\n",
    "Y_valid.columns = ['filename', 'tag']\n",
    "\n",
    "rootpath = os.path.join(train_root_path, \"train\") #文件夹目录\n",
    "X_train = []\n",
    "X_valid = []\n",
    "\n",
    "for filename in Y_train['filename']: #遍历文件夹\n",
    "    pic = image.load_img(rootpath + \"/\" + filename, target_size = (100, 100))\n",
    "    pic = image.img_to_array(pic)\n",
    "    X_train.append(pic)\n",
    "    \n",
    "for filename in Y_valid['filename']: #遍历文件夹\n",
    "    pic = image.load_img(rootpath + \"/\" + filename, target_size = (100, 100))\n",
    "    pic = image.img_to_array(pic)\n",
    "    X_valid.append(pic)\n",
    "\n",
    "    \n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "X_valid = np.array(X_valid)\n",
    "print('Train set has {} color images'.format(X_train.shape[0]))\n",
    "print('Validation set has {} color images.'.format(X_valid.shape[0]))\n",
    "\n",
    "print('Image shape:',X_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = pd.read_csv(os.path.join(test_root_path, 'image.txt'), sep='\\t', header=None)\n",
    "test_files.columns = ['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set has 14633 color images\n",
      "Image shape: (100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "rootpath = os.path.join(test_root_path, \"test\") #文件夹目录\n",
    "\n",
    "X_test = []\n",
    "\n",
    "for filename in test_files['filename']: #遍历文件夹\n",
    "    pic = image.load_img(rootpath + \"/\" + filename, target_size = (100, 100))\n",
    "    pic = image.img_to_array(pic)\n",
    "    X_test.append(pic)\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "print('Test set has {} color images'.format(X_test.shape[0]))\n",
    "print('Image shape:',X_test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tag2attr: {image tag - attribute name} pd form, merged from attr2name {attribute name}  \n",
    "tag2label: {image tag - tag name} match image tag to English name  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2attr = pd.read_csv(os.path.join(train_root_path, 'attributes_per_class.txt'),sep='\\t', header=None)\n",
    "attr2name = pd.read_csv(os.path.join(train_root_path, 'attribute_list.txt'), sep='\\t', header=None)\n",
    "tag2label = pd.read_csv(os.path.join(train_root_path, 'label_list.txt'), sep='\\t', header=None)\n",
    "tag2label.columns = ['tag', 'label']\n",
    "attr2name = attr2name.drop([0], axis=1)\n",
    "attr2name.columns = ['name']\n",
    "col_name = ['tag'] + attr2name['name'].tolist()\n",
    "tag2attr.columns = col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the provided word vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "embed_path = os.path.join(train_root_path, 'class_wordembeddings.txt')\n",
    "with open(embed_path,'r') as f:\n",
    "    for line in f:\n",
    "        word, vec = line.split(' ', 1)\n",
    "        word_dict[word] = np.array(list(map(float, vec.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Zero-shot tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags = all_train['tag'].unique()\n",
    "total_tags = tag2attr['tag'].unique()\n",
    "zero_shot_tags = list(set(total_tags) - set(train_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230 unique tags in total (Including Test Data). \n",
      "190 unique tags in Training Data. \n",
      "40 Zero-shot tags.\n"
     ]
    }
   ],
   "source": [
    "print(\"{} unique tags in total (Including Test Data). \\n{} unique tags in Training Data. \\n{} Zero-shot tags.\".format(\n",
    "    len(total_tags), len(train_tags), len(zero_shot_tags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_train_attr: {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_label_attr(df, tag2label=tag2label, tag2attr=tag2attr):\n",
    "    Y_cate = []\n",
    "    for tag in df['tag']:\n",
    "        arr = [tag2label[tag2label['tag'] == tag].iloc[0,:].tolist()[1]] + tag2attr[tag2attr['tag'] == tag].iloc[0,:].tolist()\n",
    "        Y_cate.append(arr)\n",
    "        \n",
    "    train_attr = pd.DataFrame(Y_cate)\n",
    "    col_name = ['label'] + ['tag'] + attr2name['name'].tolist()\n",
    "    train_attr.columns = col_name\n",
    "    print('Converted {} image tags into categories'.format(train_attr.shape[0]))\n",
    "    return train_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 30170 image tags into categories\n",
      "Converted 8051 image tags into categories\n"
     ]
    }
   ],
   "source": [
    "Y_train_attr = img_label_attr(Y_train)\n",
    "Y_valid_attr = img_label_attr(Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Loss Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags to Int  \n",
    "\n",
    "Convert tags (ZJLxxx) to int:  \n",
    "\n",
    "1. There are some gap in the number after ZJL, in total there are 230 tags but the largest one is \"ZJL240\"  \n",
    "2. Need to apply to_categorical() to get y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2int = {}\n",
    "\n",
    "for tag in total_tags:\n",
    "    if tag in tag2int.keys():\n",
    "        print(\"Duplicated tags\")\n",
    "    else: tag2int[tag] = len(tag2int)\n",
    "\n",
    "int2tag = {}\n",
    "\n",
    "for tag,idx in tag2int.items():\n",
    "    int2tag[idx] = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_list = list(map(lambda x: tag2int[x], Y_train['tag'].tolist()))\n",
    "Y_valid_list = list(map(lambda x: tag2int[x], Y_valid['tag'].tolist()))\n",
    "\n",
    "# one-hot encode tag types for loss calculation\n",
    "y_train = to_categorical(Y_train_list, num_classes=230)\n",
    "y_valid = to_categorical(Y_valid_list, num_classes=230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Labels\n",
    "train_word_input = [word_dict[w] for w in Y_train_attr['label']]\n",
    "valid_word_input = [word_dict[w] for w in Y_valid_attr['label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Combine_Categorical_Model():\n",
    "    \"\"\"\n",
    "    Image Feature Extraction\n",
    "    \"\"\"\n",
    "\n",
    "    # Pre-trained Xception net\n",
    "    base_model = Xception(weights='imagenet', include_top=False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # Out to match semantic size\n",
    "    img_out = Dense(300, activation='relu')(x)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Semantic Feature Extraction\n",
    "    \"\"\"\n",
    "    word_input = Input(shape=(300,), name='word_input', dtype='float32')\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Combine\n",
    "    \"\"\"\n",
    "    x = concatenate([img_out, word_input])\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Categorical Prediction\n",
    "    \"\"\"\n",
    "    prediction = Dense(230, activation='softmax')(x)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[base_model.input, word_input], \n",
    "                  outputs=prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm = Combine_Categorical_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30170 samples, validate on 8051 samples\n",
      "Epoch 1/20\n",
      "  128/30170 [..............................] - ETA: 1:01:00 - loss: 4.5635"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-22eba31e39ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = ccm.fit([X_train, np.array(train_word_input)], y_train, \n\u001b[0;32m----> 2\u001b[0;31m         validation_data=([X_valid, np.array(valid_word_input)], y_valid), epochs=20, verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = ccm.fit([X_train, np.array(train_word_input)], y_train, \n",
    "        validation_data=([X_valid, np.array(valid_word_input)], y_valid), epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE loss  \n",
    "\n",
    "####  img->semantic space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_feature_model():\n",
    "    \"\"\"\n",
    "    Image Feature Extraction\n",
    "    \"\"\"\n",
    "\n",
    "    # Pre-trained Xception net\n",
    "    base_model = Xception(weights='imagenet', include_top=False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # Out to match semantic size\n",
    "    img_out = Dense(300)(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, \n",
    "                  outputs=img_out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2sematic = img_feature_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2sematic.compile(optimizer='rmsprop', loss='MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30170 samples, validate on 8051 samples\n",
      "Epoch 1/20\n",
      "  608/30170 [..............................] - ETA: 1:10:31 - loss: 0.1560"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-35d9e621a7cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m img2sematic.fit(X_train, np.array(train_word_input), \n\u001b[0;32m----> 2\u001b[0;31m         validation_data=(X_valid, np.array(valid_word_input)), epochs=20, verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img2sematic.fit(X_train, np.array(train_word_input), \n",
    "        validation_data=(X_valid, np.array(valid_word_input)), epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = X_valid[0:10]\n",
    "Y_test = img2sematic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_dis(v1, v2):\n",
    "    return np.linalg.norm(v1-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "values = []\n",
    "\n",
    "for key, value in word_dict.items():\n",
    "    keys.append(key)\n",
    "    values.append(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "res = []\n",
    "\n",
    "for v1 in Y_test:\n",
    "    score = []\n",
    "    for v2 in values:\n",
    "        score.append(cos_dis(v1,v2))\n",
    "    \n",
    "    label = keys[score.index(min(score))]\n",
    "    res.append(tag2label[tag2label['label'] == label]['tag'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch (Not Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ZJL_DS(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        # np array\n",
    "        self.img = X\n",
    "        # series\n",
    "        self.tag = Y_train_attr['tag']\n",
    "        self.label = Y_train_attr['label']\n",
    "        # pd dataframe\n",
    "        self.attr = Y_train_attr.drop(['label', 'tag'], axis=1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_arr = self.img[idx]\n",
    "        tag = self.tag[idx]\n",
    "        label = self.label[idx]\n",
    "        attr = self.attr.iloc[idx,:]\n",
    "        info = (tag, label, attr)\n",
    "        return img_arr, info\n",
    "    \n",
    "    def show_data(self, idx):\n",
    "        img_arr = self.img[idx]\n",
    "        plt.imshow(image.array_to_img(X_train[idx]))\n",
    "        label = self.label[idx]\n",
    "        tag = self.tag[idx]\n",
    "        attr = self.attr.iloc[idx,:]\n",
    "        print(\"Image index:{} \\n\\nLabel: {} \\n\\nTag: {} \\n\\nAttribute:\\n{}\".format(idx, label, tag, attr))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image index:2505 \n",
      "\n",
      "Label: centipede \n",
      "\n",
      "Tag: ZJL11 \n",
      "\n",
      "Attribute:\n",
      "is animal               1.0\n",
      "is transportation       0.0\n",
      "is clothes              0.0\n",
      "is plant                0.0\n",
      "is tableware            0.0\n",
      "is device               0.0\n",
      "is black                0.0\n",
      "is white                0.0\n",
      "is blue                 0.0\n",
      "is brown                1.0\n",
      "is orange               0.0\n",
      "is red                  0.0\n",
      "is green                0.0\n",
      "is yellow               0.0\n",
      "has feathers            0.0\n",
      "has four legs           0.0\n",
      "has two legs            0.0\n",
      "has two arms            0.0\n",
      "is for entertainment    0.0\n",
      "is for business         0.0\n",
      "is for communication    0.0\n",
      "is for family           0.0\n",
      "is for office use       0.0\n",
      "is for personal         0.0\n",
      "is gorgeous             0.0\n",
      "is simple               0.0\n",
      "is elegant              0.0\n",
      "is cute                 0.0\n",
      "is pure                 0.0\n",
      "is naive                0.0\n",
      "Name: 2505, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = ZJL_DS(X_train, Y_train_attr)\n",
    "\n",
    "# # get train data\n",
    "# img_arr, (tag, label, attr) = train_ds[32]\n",
    "# label_embedding = word_dict[label]\n",
    "# inspect data \n",
    "train_ds.show_data(2505)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /Users/liushijing/.torch/models/resnet18-5c106cde.pth\n",
      "100%|██████████| 46827520/46827520 [09:57<00:00, 78377.23it/s] \n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self, cnn, semantic_dim=300, hidden_dim=1024):\n",
    "        super().__init__()\n",
    "        self.cnn = cnn\n",
    "        \n",
    "        for p in self.cnn.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        visual_dim = cnn.fc.out_features\n",
    "        \n",
    "        self.word_emb_transformer = nn.Sequential(*[\n",
    "            nn.Linear(semantic_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, visual_dim),\n",
    "            nn.ReLU(),\n",
    "        ])\n",
    "        \n",
    "    def forward(self, image, word):\n",
    "        self.cnn.eval()\n",
    "        visual_emb, _ = self.cnn(image)\n",
    "        semantic_emb = self.word_emb_transformer(word)\n",
    "\n",
    "        return semantic_emb, visual_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = Baseline(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [64, 3, 7, 7], but got input of size [100, 100, 3] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-6aad2fd2bb7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-e645a4606c21>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, word)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mvisual_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0msemantic_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_emb_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [64, 3, 7, 7], but got input of size [100, 100, 3] instead"
     ]
    }
   ],
   "source": [
    "img, (tag, label, attr) = train_ds[1]\n",
    "bs(torch.LongTensor(img), torch.LongTensor(embedding_dict[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = resnet18.fc.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_dim = 300\n",
    "hidden_dim = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_transformer = nn.Sequential(\n",
    "        nn.Linear(semantic_dim, hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_dim, image_dim),\n",
    "        nn.ReLU(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb_transformer(torch.FloatTensor(embedding_dict[label])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = Xception(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(300, activation='relu')(x)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Image Part\n",
    "img_model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "\n",
    "# # and a logistic layer -- let's say we have 200 classes\n",
    "# predictions = Dense(230, activation='softmax')(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_6:0' shape=(?, ?, ?, 3) dtype=float32>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features = img_model.output\n",
    "word_features = embedding_dict[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=(300,) dtype=float64>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input tensors to a Model must come from `keras.layers.Input`. Received: Tensor(\"Const_1:0\", shape=(300,), dtype=float64) (missing previous layer metadata).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-50cdf36cd269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m230\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    163\u001b[0m                                  \u001b[0;34m'must come from `keras.layers.Input`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                                  \u001b[0;34m'Received: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                                  ' (missing previous layer metadata).')\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;31m# Check that x is an input tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input tensors to a Model must come from `keras.layers.Input`. Received: Tensor(\"Const_1:0\", shape=(300,), dtype=float64) (missing previous layer metadata)."
     ]
    }
   ],
   "source": [
    "pred = Dense(230, activation='softmax')(img_features + word_features)\n",
    "\n",
    "model = Model(inputs=(base_model.input, tf.constant(word_features)), outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 1 512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, None, None, 1 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, None, None, 1 0           add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 2 32768       add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 2 1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, None, None, 2 0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, None, None, 2 0           add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 7 186368      add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 7 2912        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, None, None, 7 0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, None, None, 7 0           add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, None, None, 7 0           add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, None, None, 7 0           add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, None, None, 7 0           add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, None, None, 7 0           add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 1 745472      add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 1 4096        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          614700      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 21,476,180\n",
      "Trainable params: 614,700\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Embedding\n",
    "img_model.outpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NewLoss(nn.Module):\n",
    "    def __init__():\n",
    "        super(NewLoss,self).__init__()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Myloss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-197c95c7d49c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Myloss' is not defined"
     ]
    }
   ],
   "source": [
    "loss = Myloss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags to Int  \n",
    "\n",
    "Convert tags (ZJLxxx) to int:  \n",
    "\n",
    "1. There are some gap in the number after ZJL, in total there are 230 tags but the largest one is \"ZJL240\"  \n",
    "2. Need to apply to_categorical() to get y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2int = {}\n",
    "\n",
    "for tag in total_tags:\n",
    "    if tag in tag2int.keys():\n",
    "        print(\"Duplicated tags\")\n",
    "    else: tag2int[tag] = len(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2tag = {}\n",
    "\n",
    "for tag,idx in tag2int.items():\n",
    "    int2tag[idx] = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_list = list(map(lambda x: tag2int[x], Y_train['tag'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(Y_train_list, num_classes=230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38221, 230)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot, make_dot_from_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape= (100, 100, 3), filters=32, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(input_shape= (50, 50, 32), filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(input_shape= (25, 25, 64), filters=128, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(5000, activation='relu'))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(200))\n",
    "    \n",
    "    adam = optimizers.SGD(lr = 0.01)\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "base_model = Xception(weights='imagenet', include_top=False)\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected block14_sepconv2_act to have 4 dimensions, but got array with shape (38221, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-36d91f24903e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected block14_sepconv2_act to have 4 dimensions, but got array with shape (38221, 2)"
     ]
    }
   ],
   "source": [
    "base_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5000)              92165000  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              5001000   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 200)               200200    \n",
      "=================================================================\n",
      "Total params: 97,459,448\n",
      "Trainable params: 97,459,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 189s 3us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xception initial loss = 5.5+  \n",
    "Inception V3 initial loss = 5.3+  \n",
    "VGG 16 initial loss = 15.00+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34398 samples, validate on 3823 samples\n",
      "Epoch 1/100\n",
      "34398/34398 [==============================] - 2186s 64ms/step - loss: 6.0268 - acc: 0.0051 - val_loss: 7.4328 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " 6592/34398 [====>.........................] - ETA: 26:17 - loss: 5.1075 - acc: 0.0143"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-310dc9ba59c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, shuffle=True, batch_size = 64, validation_split = 0.1, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 3)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0xD839410B8>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.array_to_img(X_train[1].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag                     ZJL1\n",
       "is animal                  1\n",
       "is transportation          0\n",
       "is clothes                 0\n",
       "is plant                   0\n",
       "is tableware               0\n",
       "is device                  0\n",
       "is black                 0.5\n",
       "is white                   1\n",
       "is blue                    0\n",
       "is brown                   0\n",
       "is orange                  1\n",
       "is red                     0\n",
       "is green                   0\n",
       "is yellow                  1\n",
       "has feathers               0\n",
       "has four legs              0\n",
       "has two legs               0\n",
       "has two arms               0\n",
       "is for entertainment       1\n",
       "is for business            0\n",
       "is for communication       0\n",
       "is for family              0\n",
       "is for office use          0\n",
       "is for personal            0\n",
       "is gorgeous                0\n",
       "is simple                  0\n",
       "is elegant                 0\n",
       "is cute                    0\n",
       "is pure                    0\n",
       "is naive                   0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2attr[tag2attr['tag'] == Y_train[0:1]['tag'][0]].iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag                     ZJL8\n",
       "is animal                  1\n",
       "is transportation          0\n",
       "is clothes                 0\n",
       "is plant                   0\n",
       "is tableware               0\n",
       "is device                  0\n",
       "is black                   1\n",
       "is white                   0\n",
       "is blue                    0\n",
       "is brown                   0\n",
       "is orange                  0\n",
       "is red                     0\n",
       "is green                   0\n",
       "is yellow                  0\n",
       "has feathers               0\n",
       "has four legs              0\n",
       "has two legs               0\n",
       "has two arms               0\n",
       "is for entertainment       0\n",
       "is for business            0\n",
       "is for communication       0\n",
       "is for family              0\n",
       "is for office use          0\n",
       "is for personal            0\n",
       "is gorgeous                0\n",
       "is simple                  0\n",
       "is elegant                 0\n",
       "is cute                    0\n",
       "is pure                    0\n",
       "is naive                   0\n",
       "Name: 178, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_train[0:1])\n",
    "pred=pred.squeeze()\n",
    "pred_list = pred.tolist()\n",
    "pred_tag = int2tag[pred_list.index(max(pred_list))]\n",
    "tag2attr[tag2attr['tag'] == pred_tag].iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6394b0f513290f4651cc46792e5ac86.jpeg</td>\n",
       "      <td>ZJL1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   image   tag\n",
       "0  a6394b0f513290f4651cc46792e5ac86.jpeg  ZJL1"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag                     ZJL1\n",
       "is animal                  1\n",
       "is transportation          0\n",
       "is clothes                 0\n",
       "is plant                   0\n",
       "is tableware               0\n",
       "is device                  0\n",
       "is black                 0.5\n",
       "is white                   1\n",
       "is blue                    0\n",
       "is brown                   0\n",
       "is orange                  1\n",
       "is red                     0\n",
       "is green                   0\n",
       "is yellow                  1\n",
       "has feathers               0\n",
       "has four legs              0\n",
       "has two legs               0\n",
       "has two arms               0\n",
       "is for entertainment       1\n",
       "is for business            0\n",
       "is for communication       0\n",
       "is for family              0\n",
       "is for office use          0\n",
       "is for personal            0\n",
       "is gorgeous                0\n",
       "is simple                  0\n",
       "is elegant                 0\n",
       "is cute                    0\n",
       "is pure                    0\n",
       "is naive                   0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2attr[tag2attr['tag'] == \"ZJL1\"].iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>is animal</th>\n",
       "      <th>is transportation</th>\n",
       "      <th>is clothes</th>\n",
       "      <th>is plant</th>\n",
       "      <th>is tableware</th>\n",
       "      <th>is device</th>\n",
       "      <th>is black</th>\n",
       "      <th>is white</th>\n",
       "      <th>is blue</th>\n",
       "      <th>...</th>\n",
       "      <th>is for communication</th>\n",
       "      <th>is for family</th>\n",
       "      <th>is for office use</th>\n",
       "      <th>is for personal</th>\n",
       "      <th>is gorgeous</th>\n",
       "      <th>is simple</th>\n",
       "      <th>is elegant</th>\n",
       "      <th>is cute</th>\n",
       "      <th>is pure</th>\n",
       "      <th>is naive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>ZJL8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tag  is animal  is transportation  is clothes  is plant  is tableware  \\\n",
       "178  ZJL8          1                0.0           0         0             0   \n",
       "\n",
       "     is device  is black  is white  is blue    ...     is for communication  \\\n",
       "178          0       1.0       0.0      0.0    ...                      0.0   \n",
       "\n",
       "     is for family  is for office use  is for personal  is gorgeous  \\\n",
       "178            0.0                0.0              0.0          0.0   \n",
       "\n",
       "     is simple  is elegant  is cute  is pure  is naive  \n",
       "178          0           0      0.0        0         0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2attr [tag2attr['tag'] == pred_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "vgg16 = keras.applications.vgg16.VGG16(include_top=True, weights=None, input_tensor=None, \n",
    "                               input_shape=(100, 100, 3), pooling=None, classes=200)\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "\n",
    "vgg16.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected block14_sepconv2_act to have 4 dimensions, but got array with shape (38221, 200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected block14_sepconv2_act to have 4 dimensions, but got array with shape (38221, 200)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = xception.fit(X_train, y_train, shuffle=True, batch_size = 64, validation_split = 0.1, epochs = 100, verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
